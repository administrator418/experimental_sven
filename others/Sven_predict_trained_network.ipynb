{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Autoencoder and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import time\n",
    "#import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from Autoencoder_Architecture import autoencoder_512x512\n",
    "from Autoencoder_Architecture import upsample    \n",
    "from Autoencoder_Architecture import downsample\n",
    "from Autoencoder_Architecture import Autoencoder\n",
    "from Autoencoder_Architecture import evaluate\n",
    "from Autoencoder_Architecture import generate_images\n",
    "from Autoencoder_Architecture import folder_to_dataloader\n",
    "\n",
    "def load_hyperparameters(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        hyperparameters = yaml.safe_load(file)\n",
    "    return hyperparameters\n",
    "\n",
    "filepath = 'config.yaml'\n",
    "hyperparams = load_hyperparameters(filepath)\n",
    "\n",
    "# needed config parameters\n",
    "BEST_CONFIGURATION_ONLY = hyperparams['BEST_CONFIGURATION_ONLY']\n",
    "MODUS= hyperparams['MODUS']\n",
    "BEST_CONFIGURATION = hyperparams['BEST_CONFIGURATION']\n",
    "N_EPOCHS = hyperparams['N_EPOCHS']  \n",
    "MODEL_NUMBER = hyperparams['MODEL_NUMBER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = []\n",
    "\n",
    "for batch_size in [1]:\n",
    "    for learning_rate, beta_1 in [(2e-4, 0.5),(1e-4, 0.5),(2e-4, 0.9)]: # [(2e-4, 0.5), (1e-5, 0.5),(2e-4, 0.9),(1e-5, 0.9)]:\n",
    "        for use_bias_term in [True]:\n",
    "            for use_l2_loss in [True]: # only MSE before [False,True]\n",
    "                for DROPOUT_VALUE in [0.2,0.5,0.6]: # before only 0.5\n",
    "                        for KERNEL_SIZE in[3,4]:\n",
    "                            for WEIGHT_DECAY in [0, 0.004]: # default tensorflow adamW\n",
    "                                for use_skip_connections in [True]:\n",
    "                                    batches_to_plot = round(128 / batch_size)\n",
    "                                    configurations.append({\n",
    "                                        'BATCH_SIZE': batch_size,\n",
    "                                        'USE_L2_LOSS': use_l2_loss,\n",
    "                                        'N_EPOCHS': N_EPOCHS,\n",
    "                                        'BATCHES_TO_PLOT': batches_to_plot,\n",
    "                                        'USE_BIAS_TERM': use_bias_term,\n",
    "                                        'LEARNING_RATE': learning_rate,\n",
    "                                        'BETA_1': beta_1,\n",
    "                                        'USE_SKIP_CONNECTIONS': use_skip_connections,\n",
    "                                        'DROPOUT_VALUE': DROPOUT_VALUE,\n",
    "                                        'KERNEL_SIZE':KERNEL_SIZE,\n",
    "                                        'WEIGHT_DECAY': WEIGHT_DECAY,\n",
    "                                    })\n",
    "\n",
    "if BEST_CONFIGURATION_ONLY == True:\n",
    "    configurations= [configurations[BEST_CONFIGURATION]]\n",
    "else:  \n",
    "    print(f\"Use all Configurations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BATCH_SIZE': 1, 'USE_L2_LOSS': True, 'N_EPOCHS': 10, 'BATCHES_TO_PLOT': 128, 'USE_BIAS_TERM': True, 'LEARNING_RATE': 0.0002, 'BETA_1': 0.5, 'USE_SKIP_CONNECTIONS': True, 'DROPOUT_VALUE': 0.5, 'KERNEL_SIZE': 4, 'WEIGHT_DECAY': 0}\n"
     ]
    }
   ],
   "source": [
    "for config_idx, configuration in enumerate(configurations):\n",
    "    print(configuration)\n",
    "    model = Autoencoder(MODEL_NUMBER=MODEL_NUMBER, configuration=configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 256, 256, 2)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 128, 128, 64  2112        ['tf.math.truediv[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 64, 64, 128)  131712      ['sequential[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 32, 32, 256)  525568      ['sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 16, 16, 512)  2099712     ['sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 8, 8, 512)    4196864     ['sequential_3[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 4, 4, 512)    4196864     ['sequential_4[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 2, 2, 512)    4196864     ['sequential_5[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 1, 1, 512)    4196864     ['sequential_6[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 2, 2, 512)    4196864     ['sequential_7[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2, 2, 1024)   0           ['sequential_8[0][0]',           \n",
      "                                                                  'sequential_6[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)      (None, 4, 4, 512)    8391168     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 4, 4, 1024)   0           ['sequential_9[0][0]',           \n",
      "                                                                  'sequential_5[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_10 (Sequential)     (None, 8, 8, 512)    8391168     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 8, 1024)   0           ['sequential_10[0][0]',          \n",
      "                                                                  'sequential_4[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_11 (Sequential)     (None, 16, 16, 512)  8391168     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 16, 16, 1024  0           ['sequential_11[0][0]',          \n",
      "                                )                                 'sequential_3[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_12 (Sequential)     (None, 32, 32, 256)  4195584     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 512)  0           ['sequential_12[0][0]',          \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_13 (Sequential)     (None, 64, 64, 128)  1049216     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 256)  0           ['sequential_13[0][0]',          \n",
      "                                                                  'sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)     (None, 128, 128, 64  262464      ['concatenate_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 128, 128, 12  0           ['sequential_14[0][0]',          \n",
      "                                8)                                'sequential[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 256, 256, 1)  2049       ['concatenate_6[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 54,426,241\n",
      "Trainable params: 54,415,361\n",
      "Non-trainable params: 10,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model weights: only use the filename until epochXX nothing more.\n",
    "\n",
    "Example: #checkpoint_path = r'C:\\Users\\burckhardsv\\Lokale_Dateien\\results\\ditzingen_gaussian_20000img_10epochs_13_05_2024\\checkpoints\\autoencoder\\epoch_10'\n",
    "\n",
    "the it loads th right one data and index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Results\\Final_Ditzingen\\Real_Vortex_Abb08_best_config_Max_Epochs\\Dataset_Vortex_cleaned_shuffeled_best_config_abb08_ditzingen\\2024-07-03_20-53-21-303516\\checkpoints\\autoencoder\\epoch_47'\n",
    "#print(checkpoint_path)\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Image with generation of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need is a folder with the same structure as the training structure:\n",
    "\n",
    "- beam_ff: defocus image\n",
    "- beam_nf: focus image \n",
    "- phasemask some random phasemask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(predict_data, autoencoder,configuration):\n",
    "    \"\"\"Predict the Phasemask and give out all metrics and the overview image\"\"\"\n",
    "    final_test_performance = {}\n",
    "    for subset in ['predict_512']:\n",
    "        autoencoder_loss, l1_loss, l2_loss, ssim_score = evaluate(autoencoder, predict_data[subset],configuration)\n",
    "        for metric in ['autoencoder_loss','l1_loss', 'l2_loss', 'ssim_score']:\n",
    "            final_test_performance[metric] = eval(metric)\n",
    "        generate_images('final-performance', autoencoder, predict_data[subset].take(configuration['BATCHES_TO_PLOT']))\n",
    "    return autoencoder_loss, l1_loss, l2_loss, ssim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICT_DATA_PATH = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask'\n",
    "\n",
    "\n",
    "predict_data = {}  \n",
    "for subset in ['predict_512']: # Folder with the subfolders NF/FF/PM\n",
    "    nearfield = folder_to_dataloader(f'{PREDICT_DATA_PATH}/{subset}/beam_nf',configuration)\n",
    "    farfield = folder_to_dataloader(f'{PREDICT_DATA_PATH}/{subset}/beam_ff',configuration)\n",
    "    phasemask = folder_to_dataloader(f'{PREDICT_DATA_PATH}/{subset}/phasemask',configuration)\n",
    "    predict_data[subset] = tf.data.Dataset.zip((nearfield, farfield, phasemask))\n",
    "\n",
    "autoencoder_loss, l1_loss, l2_loss, ssim_score = predict(predict_data, model,configuration)\n",
    "print(f\"MAE: {l1_loss} | MSE: {l2_loss}| SSIM: {ssim_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def reverse_phasemask(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    inverted_img = Image.eval(img, lambda px: 255 - px)\n",
    "    return inverted_img\n",
    "\n",
    "image_path = r\"\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\phasemask_predicted.png\"\n",
    "inverted_image = reverse_phasemask(image_path)\n",
    "\n",
    "directory, filename = os.path.split(image_path)\n",
    "inverted_image_path = os.path.join(directory, 'reverse_' + filename)\n",
    "\n",
    "inverted_image.save(inverted_image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create compensatted phasemask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncrop_to_original(original_phasemask_path, cropped_image_path, save_path, crop_width=512, crop_height=512, rgb_value=128):\n",
    "    original_image = Image.open(original_phasemask_path)\n",
    "    cropped_image = Image.open(cropped_image_path)\n",
    "    \n",
    "    original_image_np = np.array(original_image)\n",
    "    cropped_image_np = np.array(cropped_image)\n",
    "    \n",
    "    center_y, center_x = original_image_np.shape[0] // 2, original_image_np.shape[1] // 2\n",
    "\n",
    "    start_x = max(center_x - crop_width // 2, 0)\n",
    "    start_y = max(center_y - crop_height // 2, 0)\n",
    "    \n",
    "    end_x = min(start_x + crop_width, original_image_np.shape[1])\n",
    "    end_y = min(start_y + crop_height, original_image_np.shape[0])\n",
    "    \n",
    "    new_image_np = np.full_like(original_image_np, rgb_value)\n",
    "    \n",
    "    new_image_np[start_y:end_y, start_x:end_x] = cropped_image_np\n",
    "    \n",
    "    new_image = Image.fromarray(new_image_np)\n",
    "    \n",
    "    new_image.save(save_path)\n",
    "    \n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test of the uncrop_to_original\n",
    "# original_phasemask_path = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\phasemask\\phase_mask_1.png'\n",
    "# phasemask_predicted_reverse = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\MSE_simulated\\vortex_image_2\\phasemask_predicted_reverse.png'\n",
    "# phasemask_predicted_reverse_original_size = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\test.png'\n",
    "\n",
    "# uncrop_to_original(original_phasemask_path,phasemask_predicted_reverse,phasemask_predicted_reverse_original_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the predicted phasemask back to original size\n",
    "#predicted_phasemask_reverse_path = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\phasemask_predicted_reverse.png'\n",
    "predicted_phasemask_path = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\phasemask_predicted.png'\n",
    "original_phasemask_path = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\refrence_phasemask.png' # can be one phasemask doesen't matter but needs the original size\n",
    "predicted_phasemask_original_size_path = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\predicted_phasemask_original_size.png' \n",
    "\n",
    "# recrop the predicted_phasemask_reverse to the original size 800x600\n",
    "predicted_phasemask_original_size = uncrop_to_original(original_phasemask_path,predicted_phasemask_path,predicted_phasemask_original_size_path)\n",
    "print(\"Recroped the predicted reverse phasemask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_phasemask_original_size_path= r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\predicted_phasemask_original_size.png'\n",
    "original_phasemask_path = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\Test\\phasemask\\phase_mask_1.png'\n",
    "\n",
    "predicted_phasemask_original_size = cv2.imread(predicted_phasemask_original_size_path)\n",
    "original_phasemask = cv2.imread(original_phasemask_path)\n",
    "\n",
    "predicted_phasemask_original_size = rgb2gray(predicted_phasemask_original_size)\n",
    "original_phasemask = rgb2gray(original_phasemask)\n",
    "\n",
    "plt.title(\"Beam_cropped\")\n",
    "im=plt.imshow(predicted_phasemask_original_size,cmap='gray')\n",
    "plt.colorbar(im)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Beam_cropped\")\n",
    "im=plt.imshow(original_phasemask,cmap='gray')\n",
    "plt.colorbar(im)\n",
    "plt.show()\n",
    "\n",
    "# print(predicted_phasemask_original_size.max())\n",
    "# print(original_phasemask.max())\n",
    "# print(predicted_phasemask_original_size.min())\n",
    "# print(original_phasemask.min())\n",
    "\n",
    "compensate_phasemask = abs(original_phasemask - predicted_phasemask_original_size)\n",
    "\n",
    "# print(compensate_phasemask.max())\n",
    "# print(compensate_phasemask.min())\n",
    "#print(compensate_phasemask)\n",
    "\n",
    "print(compensate_phasemask)\n",
    "\n",
    "plt.title(\"compensate_phasemask\")\n",
    "im=plt.imshow(compensate_phasemask,cmap='gray')\n",
    "plt.colorbar(im)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title(\"compensate_phasemask\")\n",
    "plt.hist(compensate_phasemask)\n",
    "plt.show()\n",
    "\n",
    "print(compensate_phasemask.min())\n",
    "print(compensate_phasemask.max())\n",
    "\n",
    "compensate_phasemask_normalized_255 = (compensate_phasemask * 255)\n",
    "\n",
    "plt.title(\"compensate_phasemask_normalized_255\")\n",
    "plt.hist(compensate_phasemask_normalized_255)\n",
    "plt.show()\n",
    "\n",
    "# save image\n",
    "output_path = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\compensate_phasemask.png'\n",
    "cv2.imwrite(output_path, compensate_phasemask_normalized_255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load compensate_phasemask_origininal_size and abbreation phasemask\n",
    "# predicted_phasemask_reverse_original_size_path = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\predicted_phasemask_reverse_original_size.png' \n",
    "# original_phasemask_path = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\10013_idx_2024-06-25 21-47-29_2588_0.png'\n",
    "\n",
    "\n",
    "# predicted_phasemask_reverse_original_size = cv2.imread(predicted_phasemask_reverse_original_size_path)\n",
    "# original_phasemask = cv2.imread(original_phasemask_path)\n",
    "\n",
    "\n",
    "\n",
    "# # check if the image are from [0:255] if not change them to that\n",
    "# print(predicted_phasemask_reverse_original_size.max())\n",
    "# print(original_phasemask.max())\n",
    "# print(predicted_phasemask_reverse_original_size.min())\n",
    "# print(original_phasemask.min())\n",
    "\n",
    "# # compensate the phasemask original phasemask - predicted_phasemask_reverse_original_size\n",
    "# # when i have two identical phasemask the image is black is this right ?\n",
    "\n",
    "# compensate_phasemask = original_phasemask - predicted_phasemask_reverse_original_size\n",
    "\n",
    "# # save image\n",
    "# output_path = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask\\compensate_phasemask.png'\n",
    "# cv2.imwrite(output_path, compensate_phasemask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(data_tuple, autoencoder, configuration):\n",
    "#     \"\"\"Predict the Phasemask and output all metrics and the overview image.\"\"\"\n",
    "#     autoencoder_loss, l1_loss, l2_loss, ssim_score = evaluate(autoencoder, data_tuple, configuration)\n",
    "#     return autoencoder_loss, l1_loss, l2_loss, ssim_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import pandas as pd\n",
    "\n",
    "# PREDICT_DATA_PATH = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Predict_Phasemask'\n",
    "# folder_test = 'predict_512'\n",
    "\n",
    "# # Load the data\n",
    "# predict_data = {}\n",
    "# for subset in [folder_test]:  # Ordner mit den Unterordnern NF/FF/PM !\n",
    "#     nearfield = folder_to_dataloader(f'{PREDICT_DATA_PATH}/{subset}/beam_nf', configuration)\n",
    "#     farfield = folder_to_dataloader(f'{PREDICT_DATA_PATH}/{subset}/beam_ff', configuration)\n",
    "#     phasemask = folder_to_dataloader(f'{PREDICT_DATA_PATH}/{subset}/phasemask', configuration)\n",
    "#     predict_data[subset] = tf.data.Dataset.zip((nearfield, farfield, phasemask))\n",
    "\n",
    "# results = []\n",
    "# for data_tuple in predict_data[folder_test]:\n",
    "#     autoencoder_loss, l1_loss, l2_loss, ssim_score = predict(predict_data[folder_test], model, configuration)\n",
    "#     results.append({\n",
    "#         \"MSE\": l1_loss,\n",
    "#         \"MAE\": l2_loss,\n",
    "#         \"SSIM\": ssim_score\n",
    "#     })\n",
    "#     print(f\"MSE: {l1_loss} | MAE: {l2_loss} | SSIM: {ssim_score}\")\n",
    "\n",
    "\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv('prediction_results.csv', index=False)\n",
    "# print(\"Finished - Ergebnisse wurden in 'prediction_results.csv' gespeichert.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
