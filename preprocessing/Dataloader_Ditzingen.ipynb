{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Random Seed simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Define parameters\n",
    "# n_indices =20000\n",
    "# seed = 42\n",
    "# output_file = 'index_shuffle_order.npy'\n",
    "\n",
    "# # Generate shuffled indices with a fixed seed\n",
    "# np.random.seed(seed)\n",
    "# shuffled_indices = np.random.permutation(n_indices) + 1  # Indices from 1 to 20000\n",
    "\n",
    "# # Save the shuffled indices\n",
    "# np.save(output_file, shuffled_indices)\n",
    "\n",
    "# print(f'Shuffled indices saved to {output_file}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out wich indicies are in both datasets after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vortex 20653\n",
      "Length of gaussian 20269\n",
      "Indices in both arrays: 20192\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "def extract_indices_from_filenames(directory):\n",
    "    indices = []\n",
    "    pattern = re.compile(r'(\\d+)_idx')\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        match = pattern.search(filename)\n",
    "        if match:\n",
    "            index = int(match.group(1))\n",
    "            indices.append(index)\n",
    "\n",
    "    return indices\n",
    "\n",
    "# directory_gaussian = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Gaussian_Abb08\\phasemask_total_index_crop'\n",
    "# directory_vortex = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Vortex_Abb08\\phasemask_total_index_crop'\n",
    "\n",
    "directory_gaussian = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Gaussian_Abb08\\phasemask_total_index_crop'\n",
    "directory_vortex = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Vortex_Abb08_New\\phasemask_preprocessed'\n",
    "\n",
    "indices_vortex = extract_indices_from_filenames(directory_vortex)\n",
    "indices_gaussian = extract_indices_from_filenames(directory_gaussian)\n",
    "\n",
    "\n",
    "print(\"Length of vortex\", len(indices_vortex))\n",
    "print(\"Length of gaussian\", len(indices_gaussian))\n",
    "\n",
    "indices_both = list(set(indices_vortex) & set(indices_gaussian))\n",
    "print(\"Indices in both arrays:\", len(indices_both))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the dataset so both gaussian and vortex have only the same coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def delete_non_matching_files(origin_dirs, indices_both):\n",
    "    for category, origin_dir in origin_dirs.items():\n",
    "        for filename in os.listdir(origin_dir):\n",
    "            match = re.search(r'(\\d+)_idx', filename)\n",
    "            if match:\n",
    "                index = int(match.group(1))\n",
    "                if index not in indices_both:\n",
    "                    os.remove(os.path.join(origin_dir, filename))\n",
    "\n",
    "origin_dirs = {\n",
    "    'camera_1': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Gaussian_Abb08\\Dataset_unwrapped\\camera_1_total_index_back_crop',\n",
    "    'camera_2': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Gaussian_Abb08\\Dataset_unwrapped\\camera_2_total_index_back_crop',\n",
    "    'phasemask': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Gaussian_Abb08\\Dataset_unwrapped\\phasemask_unwrapped_index_crop'\n",
    "}\n",
    "\n",
    "delete_non_matching_files(origin_dirs, indices_both)\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset and shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "from random import Random\n",
    "\n",
    "# Define split ratios\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "assert TRAIN_RATIO + VAL_RATIO + TEST_RATIO == 1.0, 'Invalid split sizes selected!'\n",
    "\n",
    "TARGET_FOLDER = r'C:\\Users\\burckhardsv\\Lokale_Dateien\\Schramberg\\Schramberg_Datacollection\\Schramberg_Datacollection\\Dataset_Schramberg_Vortex_Sven'\n",
    "ORIGIN_DIRS = {\n",
    "   'beam_nf': r'C:\\Users\\burckhardsv\\Lokale_Dateien\\Schramberg\\Schramberg_Datacollection\\Schramberg_Datacollection\\camera_1_noise_crop',\n",
    "   'beam_ff': r'C:\\Users\\burckhardsv\\Lokale_Dateien\\Schramberg\\Schramberg_Datacollection\\Schramberg_Datacollection\\camera_2_noise_crop',\n",
    "   'phasemask': r'C:\\Users\\burckhardsv\\Lokale_Dateien\\Schramberg\\Schramberg_Datacollection\\Schramberg_Datacollection\\phase_unwrapped_index_crop'\n",
    "}\n",
    "\n",
    "# TARGET_FOLDER = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datasets\\Dataset_Gaussian_shuffle_cleaned'\n",
    "# ORIGIN_DIRS = {\n",
    "#    'beam_nf': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Gaussian_Abb08\\camera_1_total_index_back_crop_cleaned',\n",
    "#    'beam_ff': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Gaussian_Abb08\\camera_2_total_index_back_crop_cleaned',\n",
    "#    'phasemask': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Gaussian_Abb08\\phasemask_total_index_crop_cleaned'\n",
    "# }\n",
    "\n",
    "# TARGET_FOLDER = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datasets\\Dataset_Gaussian_real_ditzingen_Abb08_shuffle_cleaned_unwrapped'\n",
    "# ORIGIN_DIRS = {\n",
    "#    'beam_nf': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Gaussian_Abb08\\Dataset_unwrapped\\camera_1_total_index_back_crop',\n",
    "#    'beam_ff': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Gaussian_Abb08\\Dataset_unwrapped\\camera_2_total_index_back_crop',\n",
    "#    'phasemask': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Gaussian_Abb08\\Dataset_unwrapped\\phasemask_unwrapped_index_crop'\n",
    "# }\n",
    "\n",
    "#TARGET_FOLDER = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datasets\\Dataset_Vortex_shuffle_cleaned'\n",
    "#ORIGIN_DIRS = {\n",
    "#   'beam_nf': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Vortex_Abb08\\camera_1_total_index_noise_crop_cleaned',\n",
    "#   'beam_ff': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Vortex_Abb08\\camera_2_total_index_noise_crop_cleaned',\n",
    "#   'phasemask': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Vortex_Abb08\\phasemask_total_index_crop_cleaned'\n",
    "#}\n",
    "\n",
    "\n",
    "# TARGET_FOLDER = r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datasets\\Dataset_Vortex_20000imgs_shuffle_cleaned_v2_unwrapped'\n",
    "# ORIGIN_DIRS = {\n",
    "#   'beam_nf': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Vortex_Abb08_New\\camera_1_crop_cleaned_unwrapped',\n",
    "#   'beam_ff': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Vortex_Abb08_New\\camera_2_crop_cleaned_unwrapped',\n",
    "#   'phasemask': r'\\\\srvditz1\\lac\\Studenten\\AE_VoE_Stud\\Sven Burckhard\\Datenaufnahme\\Raw_Data_Ditzingen_Vortex_Abb08_New\\phasemask_unwrapped_index_crop'\n",
    "# }\n",
    "\n",
    "subdirs = ['train', 'val', 'test']\n",
    "categories = ['beam_ff', 'beam_nf', 'phasemask']\n",
    "for subdir in subdirs:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(TARGET_FOLDER, subdir, category), exist_ok=True)\n",
    "\n",
    "# suffle the data between train test val innerhalb von train müssen die indexe aber gleich sein phasemask, beam_nf, beam_ff müssen die gleichen Indexe haben!\n",
    "def create_dataset():\n",
    "    all_files = {category: sorted(glob.glob(os.path.join(path, '*'))) for category, path in ORIGIN_DIRS.items()}\n",
    "    \n",
    "    file_indices = list(range(len(all_files['beam_nf'])))\n",
    "    Random(42).shuffle(file_indices)\n",
    "\n",
    "    num_files = len(file_indices)\n",
    "    train_end = int(num_files * TRAIN_RATIO)\n",
    "    val_end = train_end + int(num_files * VAL_RATIO)\n",
    "    \n",
    "    splits = {\n",
    "        'train': file_indices[:train_end],\n",
    "        'val': file_indices[train_end:val_end],\n",
    "        'test': file_indices[val_end:]\n",
    "    }\n",
    "\n",
    "    for split, indices in splits.items():\n",
    "        for category in categories:\n",
    "            for index in indices:\n",
    "                src_file = all_files[category][index]\n",
    "                dest_file = os.path.join(TARGET_FOLDER, split, category, os.path.basename(src_file))\n",
    "                shutil.copyfile(src_file, dest_file)\n",
    "\n",
    "create_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from random import Random\n",
    "\n",
    "# Define split ratios\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "assert TRAIN_RATIO + VAL_RATIO + TEST_RATIO == 1.0, 'Invalid split sizes selected!'\n",
    "\n",
    "TARGET_FOLDER = r'C:\\Users\\burckhardsv\\Lokale_Dateien\\Schramberg\\Schramberg_Datacollection\\Schramberg_Datacollection\\Dataset_Schramberg_Vortex_Sven_TEST'\n",
    "ORIGIN_DIRS = {\n",
    "    'beam_nf': r'C:\\Users\\burckhardsv\\Lokale_Dateien\\Schramberg\\Schramberg_Datacollection\\Schramberg_Datacollection\\camera_1_noise_crop',\n",
    "    'beam_ff': r'C:\\Users\\burckhardsv\\Lokale_Dateien\\Schramberg\\Schramberg_Datacollection\\Schramberg_Datacollection\\camera_2_noise_crop',\n",
    "    'phasemask': r'C:\\Users\\burckhardsv\\Lokale_Dateien\\Schramberg\\Schramberg_Datacollection\\Schramberg_Datacollection\\phase_unwrapped_index_crop'\n",
    "}\n",
    "\n",
    "subdirs = ['train', 'val', 'test']\n",
    "categories = ['beam_ff', 'beam_nf', 'phasemask']\n",
    "\n",
    "# Create directories for the splits and categories\n",
    "for subdir in subdirs:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(TARGET_FOLDER, subdir, category), exist_ok=True)\n",
    "\n",
    "# Function to extract the common index from a filename\n",
    "def extract_index(filename):\n",
    "    # Assuming file names start with the index, e.g., '1_idx_...'\n",
    "    return filename.split('_')[0]\n",
    "\n",
    "def create_dataset():\n",
    "    # Gather all files for each category\n",
    "    all_files = {category: sorted(glob.glob(os.path.join(path, '*'))) for category, path in ORIGIN_DIRS.items()}\n",
    "\n",
    "    # Create a dictionary to store the files by their common index\n",
    "    indexed_files = {}\n",
    "    for category, files in all_files.items():\n",
    "        for file in files:\n",
    "            filename = os.path.basename(file)\n",
    "            index = extract_index(filename)\n",
    "            if index not in indexed_files:\n",
    "                indexed_files[index] = {}\n",
    "            indexed_files[index][category] = file\n",
    "\n",
    "    # Filter out indices that don't have files in all categories\n",
    "    valid_indices = [index for index, file_dict in indexed_files.items() if len(file_dict) == len(categories)]\n",
    "\n",
    "    # Shuffle the valid indices\n",
    "    Random(42).shuffle(valid_indices)\n",
    "\n",
    "    # Split indices based on the given train/val/test ratios\n",
    "    num_files = len(valid_indices)\n",
    "    train_end = int(num_files * TRAIN_RATIO)\n",
    "    val_end = train_end + int(num_files * VAL_RATIO)\n",
    "    \n",
    "    splits = {\n",
    "        'train': valid_indices[:train_end],\n",
    "        'val': valid_indices[train_end:val_end],\n",
    "        'test': valid_indices[val_end:]\n",
    "    }\n",
    "\n",
    "    # Copy the files into the respective split directories\n",
    "    for split, indices in splits.items():\n",
    "        for index in indices:\n",
    "            for category in categories:\n",
    "                src_file = indexed_files[index][category]\n",
    "                dest_file = os.path.join(TARGET_FOLDER, split, category, os.path.basename(src_file))\n",
    "                shutil.copyfile(src_file, dest_file)\n",
    "\n",
    "#create_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Origin folder must contain a beam folder with all NEarfield and Farfiel images and a folder with all Phasemasks.cd\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Completed:     1 / 20000] Copying instance \"10651\" to \"train/idx-1__img-10651.png\"\n",
      "[Completed:     2 / 20000] Copying instance \"2042\" to \"train/idx-2__img-2042.png\"\n",
      "[Completed:     3 / 20000] Copying instance \"8669\" to \"train/idx-3__img-8669.png\"\n",
      "[Completed:     4 / 20000] Copying instance \"1115\" to \"train/idx-4__img-1115.png\"\n",
      "[Completed:     5 / 20000] Copying instance \"13903\" to \"train/idx-5__img-13903.png\"\n",
      "[Completed:     6 / 20000] Copying instance \"11964\" to \"train/idx-6__img-11964.png\"\n",
      "[Completed:     7 / 20000] Copying instance \"11073\" to \"train/idx-7__img-11073.png\"\n",
      "[Completed:     8 / 20000] Copying instance \"3003\" to \"train/idx-8__img-3003.png\"\n",
      "[Completed:     9 / 20000] Copying instance \"19772\" to \"train/idx-9__img-19772.png\"\n",
      "[Completed:    10 / 20000] Copying instance \"8116\" to \"train/idx-10__img-8116.png\"\n",
      "[Completed:    11 / 20000] Copying instance \"3526\" to \"train/idx-11__img-3526.png\"\n",
      "[Completed:    21 / 20000] Copying instance \"9924\" to \"train/idx-21__img-9924.png\"\n",
      "[Completed:    31 / 20000] Copying instance \"3942\" to \"train/idx-31__img-3942.png\"\n",
      "[Completed:    41 / 20000] Copying instance \"15441\" to \"train/idx-41__img-15441.png\"\n",
      "[Completed:   101 / 20000] Copying instance \"15305\" to \"train/idx-101__img-15305.png\"\n",
      "[Completed:   201 / 20000] Copying instance \"15485\" to \"train/idx-201__img-15485.png\"\n",
      "[Completed:   301 / 20000] Copying instance \"18912\" to \"train/idx-301__img-18912.png\"\n",
      "[Completed:   401 / 20000] Copying instance \"2767\" to \"train/idx-401__img-2767.png\"\n",
      "[Completed:  1001 / 20000] Copying instance \"10400\" to \"train/idx-1001__img-10400.png\"\n",
      "[Completed:  2001 / 20000] Copying instance \"16271\" to \"train/idx-2001__img-16271.png\"\n",
      "[Completed:  3001 / 20000] Copying instance \"13206\" to \"train/idx-3001__img-13206.png\"\n",
      "[Completed:  4001 / 20000] Copying instance \"5895\" to \"train/idx-4001__img-5895.png\"\n",
      "[Completed:  5001 / 20000] Copying instance \"5515\" to \"train/idx-5001__img-5515.png\"\n",
      "[Completed:  6001 / 20000] Copying instance \"17219\" to \"train/idx-6001__img-17219.png\"\n",
      "[Completed:  7001 / 20000] Copying instance \"14391\" to \"train/idx-7001__img-14391.png\"\n",
      "[Completed:  8001 / 20000] Copying instance \"14790\" to \"train/idx-8001__img-14790.png\"\n",
      "[Completed:  9001 / 20000] Copying instance \"16868\" to \"train/idx-9001__img-16868.png\"\n",
      "[Completed: 10001 / 20000] Copying instance \"9435\" to \"train/idx-10001__img-9435.png\"\n",
      "[Completed: 11001 / 20000] Copying instance \"3741\" to \"train/idx-11001__img-3741.png\"\n",
      "[Completed: 12001 / 20000] Copying instance \"5678\" to \"train/idx-12001__img-5678.png\"\n",
      "[Completed: 13001 / 20000] Copying instance \"8762\" to \"train/idx-13001__img-8762.png\"\n",
      "[Completed: 14001 / 20000] Copying instance \"179\" to \"val/idx-14001__img-179.png\"\n",
      "[Completed: 15001 / 20000] Copying instance \"17808\" to \"val/idx-15001__img-17808.png\"\n",
      "[Completed: 16001 / 20000] Copying instance \"1263\" to \"val/idx-16001__img-1263.png\"\n",
      "[Completed: 17001 / 20000] Copying instance \"17182\" to \"test/idx-17001__img-17182.png\"\n",
      "[Completed: 18001 / 20000] Copying instance \"3717\" to \"test/idx-18001__img-3717.png\"\n",
      "[Completed: 19001 / 20000] Copying instance \"4381\" to \"test/idx-19001__img-4381.png\"\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load shuffled indices\n",
    "shuffle_file = r'C:\\Users\\burckhardsv\\Lokale_Dateien\\Playground.schwartzma\\Beam_Shaping_using_ML\\experimental_sven\\preprocessing\\index_shuffle_order.npy'\n",
    "shuffled_indices = np.load(shuffle_file)\n",
    "\n",
    "# Define split (train / val / test) and origin and target directory\n",
    "TRAIN = 0.7\n",
    "VAL = 0.15\n",
    "TEST = 0.15\n",
    "TARGET_FOLDER = r'C:\\Users\\burckhardsv\\Daten\\Dataset_Vortex_Simulated_Unwrapped'\n",
    "ORIGIN = r'C:\\Users\\burckhardsv\\Daten\\Raw_Data_Vortex_Intensity_Unwrapped'\n",
    "\n",
    "# Check if split sizes sum up to 1\n",
    "assert TRAIN + VAL + TEST == 1.0, 'Invalid split sizes selected!'\n",
    "\n",
    "# Create target folder(s)\n",
    "subdirs = ['train', 'val', 'test']\n",
    "categories = ['beam_ff', 'beam_nf', 'phasemask']\n",
    "for subdir in subdirs:\n",
    "    for category in categories:\n",
    "        dir_path = os.path.join(TARGET_FOLDER, subdir, category)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "def extract_fileindex(filename):\n",
    "    filename_short = filename.split('\\\\')[-1].split('/')[-1].split('.')[0]\n",
    "    return filename_short[:-2] if filename_short[-2] == 'd' else filename_short[:-1]\n",
    "\n",
    "# Collect files\n",
    "files = list(glob.glob(ORIGIN + '/beam/*'))\n",
    "file_indices = list(set([extract_fileindex(file) for file in files]))\n",
    "n_instances = len(file_indices)\n",
    "n_digits = len(str(n_instances))  # required for logging\n",
    "assert len(files) == 2 * n_instances, 'Your \"beam\" folder does not meet the requirements!'\n",
    "\n",
    "# Calculate how many instances to put into which set\n",
    "n_instances_train = round(TRAIN * n_instances)\n",
    "n_instances_val = round(VAL * n_instances)\n",
    "\n",
    "# Loop through shuffled files\n",
    "for i, fileindex in enumerate(shuffled_indices):\n",
    "\n",
    "    idx = i + 1  # index is prefixed into the target filename to ensure shuffling\n",
    "\n",
    "    # Select subset (train / test / val)\n",
    "    if idx <= n_instances_train:\n",
    "        subset = 'train'\n",
    "    elif idx <= n_instances_train + n_instances_val:\n",
    "        subset = 'val'\n",
    "    else:\n",
    "        subset = 'test'\n",
    "    \n",
    "    try:\n",
    "        # Copy files with nf and ff switched\n",
    "        shutil.copyfile(f'{ORIGIN}/beam/{fileindex}df.png', f'{TARGET_FOLDER}/{subset}/beam_ff/idx-{idx}__img-{fileindex}.png')\n",
    "        shutil.copyfile(f'{ORIGIN}/beam/{fileindex}f.png', f'{TARGET_FOLDER}/{subset}/beam_nf/idx-{idx}__img-{fileindex}.png')\n",
    "        #shutil.copyfile(f'{ORIGIN}/phasemask/Phase{fileindex}.png', f'{TARGET_FOLDER}/{subset}/phasemask/idx-{idx}__img-{fileindex}.png') # old\n",
    "        shutil.copyfile(f'{ORIGIN}/phasemask/{fileindex}.png', f'{TARGET_FOLDER}/{subset}/phasemask/idx-{idx}__img-{fileindex}.png') # new\n",
    "        # Show status\n",
    "        if i < 10 or (i % 10 == 0 and i < 50) or (i % 100 == 0 and i < 500) or (i % 1000 == 0):\n",
    "            print(f'[Completed: {idx:{n_digits}} / {n_instances}] Copying instance \"{fileindex}\" to \"{subset}/idx-{idx}__img-{fileindex}.png\"')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'ERROR: Could not copy file {fileindex} (new index: {idx}): {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test indices in a dataset, all indiceies should be the same in the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vortex 9634\n",
      "Length of gaussian 9634\n",
      "Indices not in both arrays: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def extract_indices_from_filenames(directory):\n",
    "    indices = []\n",
    "    pattern = re.compile(r'(\\d+)_idx')\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        match = pattern.search(filename)\n",
    "        if match:\n",
    "            index = int(match.group(1))\n",
    "            indices.append(index)\n",
    "\n",
    "    return indices\n",
    "\n",
    "directory_gaussian = r'C:\\Users\\burckhardsv\\Lokale_Dateien\\Schramberg\\Schramberg_Datacollection\\Schramberg_Datacollection\\Dataset_Schramberg_Vortex_Sven_Test\\train\\beam_ff'\n",
    "directory_vortex = r'C:\\Users\\burckhardsv\\Lokale_Dateien\\Schramberg\\Schramberg_Datacollection\\Schramberg_Datacollection\\Dataset_Schramberg_Vortex_Sven_Test\\train\\phasemask'\n",
    "\n",
    "indices_vortex = extract_indices_from_filenames(directory_vortex)\n",
    "indices_gaussian = extract_indices_from_filenames(directory_gaussian)\n",
    "\n",
    "print(\"Length of vortex\", len(indices_vortex))\n",
    "print(\"Length of gaussian\", len(indices_gaussian))\n",
    "\n",
    "# Berechnung der Indizes, die nur in einer der Listen vorkommen\n",
    "indices_not_in_both = list(set(indices_vortex).symmetric_difference(set(indices_gaussian)))\n",
    "print(\"Indices not in both arrays:\", indices_not_in_both)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
